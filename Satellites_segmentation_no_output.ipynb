{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCDcE_zSQ2ye"
      },
      "source": [
        "# Сегментация космических объектов \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q0ZfqmjT8VJ"
      },
      "source": [
        "## Загрузка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APg9y9gCZ_8h"
      },
      "source": [
        "Набор данных - [Final_dataset](https://drive.google.com/drive/u/0/folders/1Q1wR9aBFCyeFEYa3wwyXNu9wk_fZdzUm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "→ Данный датасет состоит из 3 116 изображений и масок как синтезированных, так и реальных изображений спутников и космических станций (размер масок — 1 280x720).\n",
        "\n",
        "→ Каждый космический аппарат разделён максимум на три части, включая корпус, солнечную панель и антенну, помеченные, соответственно, тремя цветами — зелёным, красным и синим.\n",
        "\n",
        "→ В папке images находятся изображения, в папке mask — маски объектов.\n",
        "\n",
        "→ Изображение с индексом 0-1002 имеет точную маску, а изображения с индексом 1003-3116 — грубую маску.\n",
        "\n",
        "→ Наборы данных разделены на две части: обучающую выборку, включая 403 точные маски из индексов 0-402, и 2 114 грубых масок из индекса 1003-3116.\n",
        "\n",
        "→ Набор данных val включает 600 изображений с точной маской, проиндексированных от 403 до 1002."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_nIQ-L0aXfi"
      },
      "outputs": [],
      "source": [
        "images_path = 'Final_dataset/images/'\n",
        "mask_path = 'Final_dataset/mask/'\n",
        "all_bbox = 'Final_dataset/all_bbox.txt'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5g-TGxWGa2WP"
      },
      "source": [
        "## Импортируем нужные библиотеки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SePCyDfIa4jg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import json\n",
        "from PIL import Image\n",
        "\n",
        "import albumentations as A\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.patches as patches\n",
        "import numpy as np\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchmetrics\n",
        "\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "from pytorch_lightning.callbacks import (\n",
        "    EarlyStopping,\n",
        "    LearningRateMonitor,\n",
        "    ModelCheckpoint,\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Знакомство с данными"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "display(len(os.listdir('Final_dataset/images/train')))\n",
        "display(len(os.listdir('Final_dataset/images/val')))\n",
        "display(len(os.listdir('Final_dataset/mask/train')))\n",
        "display(len(os.listdir('Final_dataset/mask/val')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "display(len(os.listdir('Final_dataset/mask/val'))+len(os.listdir('Final_dataset/mask/train')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(all_bbox, 'r') as f:\n",
        "    dct = json.load(f)\n",
        "\n",
        "all_bbox_df = pd.DataFrame.from_dict(dct, orient='index')\n",
        "all_bbox_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_bbox_df[all_bbox_df[1].notna()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Видим что в представленном датасете присутствует 360 изображений, на которых изображено более 1 космического аппарата."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Пример изображения с точной маской"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "img1 = mpimg.imread('Final_dataset/images/train/img_resize_3.png')\n",
        "img2 = mpimg.imread('Final_dataset/mask/train/img_resize_3_mask.png')\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(20, 5))\n",
        "ax[0].imshow(img1)\n",
        "ax[0].axis('off')\n",
        "xmin, ymin, xmax, ymax = all_bbox_df.loc['3'][0]\n",
        "rect = patches.Rectangle((xmin, ymin), (xmax-xmin), (ymax-ymin), linewidth=1, edgecolor='r', facecolor='none')\n",
        "ax[0].add_patch(rect)\n",
        "xmin, ymin, xmax, ymax = all_bbox_df.loc['3'][1]\n",
        "rect = patches.Rectangle((xmin, ymin), (xmax-xmin), (ymax-ymin), linewidth=1, edgecolor='r', facecolor='none')\n",
        "ax[0].add_patch(rect)\n",
        "\n",
        "ax[1].imshow(img2)\n",
        "ax[1].axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Пример изображения с грубой маской"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "img1 = mpimg.imread('Final_dataset/images/train/img_resize_1014.png')\n",
        "img2 = mpimg.imread('Final_dataset/mask/train/img_resize_1014_mask.png')\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(20, 5))\n",
        "ax[0].imshow(img1)\n",
        "ax[0].axis('off')\n",
        "xmin, ymin, xmax, ymax = all_bbox_df.loc['1014'][0]\n",
        "rect = patches.Rectangle((xmin, ymin), (xmax-xmin), (ymax-ymin), linewidth=1, edgecolor='r', facecolor='none')\n",
        "ax[0].add_patch(rect)\n",
        "xmin, ymin, xmax, ymax = all_bbox_df.loc['1014'][1]\n",
        "rect = patches.Rectangle((xmin, ymin), (xmax-xmin), (ymax-ymin), linewidth=1, edgecolor='r', facecolor='none')\n",
        "ax[0].add_patch(rect)\n",
        "xmin, ymin, xmax, ymax = all_bbox_df.loc['1014'][2]\n",
        "rect = patches.Rectangle((xmin, ymin), (xmax-xmin), (ymax-ymin), linewidth=1, edgecolor='r', facecolor='none')\n",
        "ax[0].add_patch(rect)\n",
        "xmin, ymin, xmax, ymax = all_bbox_df.loc['1014'][3]\n",
        "rect = patches.Rectangle((xmin, ymin), (xmax-xmin), (ymax-ymin), linewidth=1, edgecolor='r', facecolor='none')\n",
        "ax[0].add_patch(rect)\n",
        "\n",
        "ax[1].imshow(img2)\n",
        "ax[1].axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Можно заметить что при грубой маске игнорируются мелкие детали, антенны "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Преобразование масок в аннотации YOLO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Пример формата аннотации:** \n",
        "- 8 0.575 0.381474 0.5875 0.377771 0.599996 0.355556 0.602079 0.311111 0.595833 0.300007 0.566667 0.300007 0.564583 0.314822 0.554167 0.314822 0.55 0.325933 0.535417 0.329637 ... Xn Yn\n",
        "\n",
        "***Где первое число кодирует класс ~~, следующие четыре кодируют информацию о ограничивающей рамке~~. Остальные числа кодируют границу объекта, который мы пытаемся сегментировать. Начиная с 6-го числа, у нас есть разделенные пробелом координаты x-y для каждой точки на границе объекта для маски сегментации.***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def mask_to_annotation(img_path):\n",
        "    mask = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "    _, mask = cv2.threshold(mask, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Создадим бинаризованные маски для каждого цвета\n",
        "    lower_green = np.array([0, 100, 0])\n",
        "    upper_green = np.array([100, 255, 100])\n",
        "    green_mask = cv2.inRange(mask, lower_green, upper_green)\n",
        "\n",
        "    lower_red = np.array([0, 0, 100])\n",
        "    upper_red = np.array([100, 100, 255])\n",
        "    red_mask = cv2.inRange(mask, lower_red, upper_red)\n",
        "\n",
        "    lower_blue = np.array([100, 0, 0])\n",
        "    upper_blue = np.array([255, 100, 100])\n",
        "    blue_mask = cv2.inRange(mask, lower_blue, upper_blue)\n",
        "\n",
        "    # В масках были обнаружены шумы, необходимо их устранить\n",
        "    kernel = np.ones((3, 3), np.uint8)  # Ядро размером 3x3\n",
        "    green_mask = cv2.erode(green_mask, kernel, iterations=1)\n",
        "    green_mask = cv2.dilate(green_mask, kernel, iterations=1)\n",
        "\n",
        "    blue_mask = cv2.erode(blue_mask, kernel, iterations=1)\n",
        "    blue_mask = cv2.dilate(blue_mask, kernel, iterations=1)\n",
        "\n",
        "    red_mask = cv2.erode(red_mask, kernel, iterations=1)\n",
        "    red_mask = cv2.dilate(red_mask, kernel, iterations=1)\n",
        "\n",
        "    # Найдем контуры объектов в каждой маске\n",
        "    green_contours, _ = cv2.findContours(green_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    red_contours, _ = cv2.findContours(red_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    blue_contours, _ = cv2.findContours(blue_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    with open('Final_dataset/annotations/' + img_path.split('/')[-2] + '/img_resize_' + img_path.split('_')[-2] + '.txt', 'w') as f:\n",
        "        for i, contour in enumerate(green_contours):\n",
        "            # Извлекаем координаты контура\n",
        "            epsilon = 0.001 * cv2.arcLength(contour, True)\n",
        "            approx = cv2.approxPolyDP(contour, epsilon, True)\n",
        "            coords = approx.reshape(-1, 2).tolist()\n",
        "\n",
        "            # Контур должен начинаться и заканчиваться в одной точке\n",
        "            coords.append(coords[0])\n",
        "\n",
        "            # Нормализуем координаты точек контура\n",
        "            coords = np.array(coords) / [mask.shape[1], mask.shape[0]]\n",
        "\n",
        "            # Записываем координаты в txt-файл\n",
        "            f.write(f'{0} ')  # Индекс класса (зеленый)\n",
        "            x, y, w, h = cv2.boundingRect(contour)\n",
        "            #f.write(f'{x / mask.shape[1]} {y / mask.shape[0]} {(x + w) / mask.shape[1]} {(y + h) / mask.shape[0]} ')  # Ограничивающая рамка\n",
        "            f.write(' '.join(map(str, np.array(coords).flatten())) + '\\n')  # Координаты точек контура\n",
        "\n",
        "        # Повторяем для остальных цветов\n",
        "        for i, contour in enumerate(red_contours):\n",
        "\n",
        "            epsilon = 0.001 * cv2.arcLength(contour, True)\n",
        "            approx = cv2.approxPolyDP(contour, epsilon, True)\n",
        "            coords = approx.reshape(-1, 2).tolist()\n",
        "\n",
        "            coords.append(coords[0])\n",
        "\n",
        "            coords = np.array(coords) / [mask.shape[1], mask.shape[0]]\n",
        "\n",
        "            f.write(f'{1} ')  # Индекс класса (красный)\n",
        "            x, y, w, h = cv2.boundingRect(contour)\n",
        "            #f.write(f'{x / mask.shape[1]} {y / mask.shape[0]} {(x + w) / mask.shape[1]} {(y + h) / mask.shape[0]} ')  # Ограничивающая рамка\n",
        "            f.write(' '.join(map(str, np.array(coords).flatten())) + '\\n')  # Координаты точек контура\n",
        "\n",
        "        for i, contour in enumerate(blue_contours):\n",
        "\n",
        "            epsilon = 0.001 * cv2.arcLength(contour, True)\n",
        "            approx = cv2.approxPolyDP(contour, epsilon, True)\n",
        "            coords = approx.reshape(-1, 2).tolist()\n",
        "            \n",
        "            coords.append(coords[0])\n",
        "            \n",
        "            coords = np.array(coords) / [mask.shape[1], mask.shape[0]]\n",
        "\n",
        "            f.write(f'{2} ')  # Индекс класса (синий)\n",
        "            x, y, w, h = cv2.boundingRect(contour)\n",
        "            #f.write(f'{x / mask.shape[1]} {y / mask.shape[0]} {(x + w) / mask.shape[1]} {(y + h) / mask.shape[0]} ')  # Ограничивающая рамка\n",
        "            f.write(' '.join(map(str, np.array(coords).flatten())) + '\\n')  # Координаты точек контура"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mask_to_annotation('Final_dataset/mask/train/img_resize_1014_mask.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Отрисуем получившуюся аннотацию"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def draw_annotations(image, annotations_file):\n",
        "\n",
        "    plt.figure(figsize=(15, 10))\n",
        "\n",
        "    # Создайте словарь для соответствия индекса класса цвету\n",
        "    class_colors = {\n",
        "        0: 'green',  # Зеленый для корпуса\n",
        "        1: 'red',    # Красный для солнечных панелей\n",
        "        2: 'blue'    # Синий для антенн\n",
        "    }\n",
        "\n",
        "    # Откройте txt-файл для чтения\n",
        "    with open(annotations_file, 'r') as f:\n",
        "        for line in f:\n",
        "            # Извлеките данные из строчки\n",
        "            data = list(map(float, line.split()))\n",
        "            class_id = int(data[0])\n",
        "            #x1, y1, x2, y2 = data[1:5]\n",
        "            #coords = np.array(data[5:]).reshape(-1, 2)\n",
        "            coords = np.array(data[1:]).reshape(-1, 2)\n",
        "\n",
        "            # Денормализуйте координаты точек контура\n",
        "            coords = coords * [image.shape[1], image.shape[0]]\n",
        "\n",
        "            # Преобразуйте координаты в целые числа\n",
        "            #x1, y1, x2, y2 = map(int, [x1 * image.shape[1], y1 * image.shape[0], x2 * image.shape[1], y2 * image.shape[0]])\n",
        "            coords = coords.astype(np.int32)\n",
        "\n",
        "            # Отрисуйте ограничивающую рамку\n",
        "            #rect = patches.Rectangle((x1, y1), x2 - x1, y2 - y1, linewidth=2, edgecolor=class_colors[class_id], facecolor='none')\n",
        "            #plt.gca().add_patch(rect)\n",
        "\n",
        "            # Отрисуйте границы\n",
        "            plt.plot(coords[:, 0], coords[:, 1], color=class_colors[class_id], linewidth=1)\n",
        "\n",
        "    # Отобразите изображение\n",
        "    \n",
        "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image = cv2.imread('Final_dataset/images/train/img_resize_1014.png')\n",
        "draw_annotations(image, 'Final_dataset/annotations/train/img_resize_1014.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Сформируем аннотации к каждому изображению"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_mask_path = os.listdir('Final_dataset/mask/train')\n",
        "val_mask_path = os.listdir('Final_dataset/mask/val')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for mask in train_mask_path:\n",
        "    mask_to_annotation('Final_dataset/mask/train/' + mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for mask in val_mask_path:\n",
        "    mask_to_annotation('Final_dataset/mask/val/' + mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image = cv2.imread('Final_dataset/images/val/img_resize_784.png')\n",
        "draw_annotations(image, 'Final_dataset/annotations/val/img_resize_784.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Обучение модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!yolo task=segment mode=train epochs=10 data=satellite_dataset.yaml model=yolov8s-seg.pt imgsz=640 batch=8\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 38/38 [00:06<00:00,  6.24it/s]\n",
        "                   all        600       2523      0.764      0.643      0.693      0.518      0.788      0.658      0.712      0.525\n",
        "                  body        600        916      0.798      0.648      0.707       0.49      0.824      0.666      0.714      0.489\n",
        "           solar_panel        600       1228      0.862      0.801      0.864      0.707      0.873      0.809       0.87      0.721\n",
        "                antena        600        379      0.632       0.48      0.508      0.355      0.665      0.499      0.551      0.364\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image = Image.open('runs/segment/train4/confusion_matrix_normalized.png')\n",
        "scale = 0.3\n",
        "new_width = int(image.width * scale)\n",
        "new_height = int(image.height * scale)\n",
        "\n",
        "# Изменяем размер изображения\n",
        "resized_image = image.resize((new_width, new_height))\n",
        "\n",
        "# Отображаем измененное изображение\n",
        "display(resized_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image = Image.open('runs/segment/train4/results.png')\n",
        "scale = 0.4\n",
        "new_width = int(image.width * scale)\n",
        "new_height = int(image.height * scale)\n",
        "\n",
        "# Изменяем размер изображения\n",
        "resized_image = image.resize((new_width, new_height))\n",
        "\n",
        "# Отображаем измененное изображение\n",
        "display(resized_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "img1 = mpimg.imread('runs/segment/train4/val_batch0_labels.jpg')\n",
        "img2 = mpimg.imread('runs/segment/train4/val_batch0_pred.jpg')\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(30, 30))\n",
        "ax[0].imshow(img1)\n",
        "ax[0].axis('off')\n",
        "ax[0].set_title('labels')\n",
        "\n",
        "ax[1].imshow(img2)\n",
        "ax[1].axis('off')\n",
        "ax[1].set_title('pred')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Видим что модель отрабатывает не идеально, попробуем обучить её на большем количестве эпох."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!yolo task=segment mode=train epochs=100 data=satellite_dataset.yaml model=yolov8s-seg.pt imgsz=640 batch=8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Результаты обучения модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lAxpkCbgRsJ"
      },
      "outputs": [],
      "source": [
        "image = Image.open('runs/segment/train7/confusion_matrix_normalized.png')\n",
        "scale = 0.3\n",
        "new_width = int(image.width * scale)\n",
        "new_height = int(image.height * scale)\n",
        "\n",
        "# Изменяем размер изображения\n",
        "resized_image = image.resize((new_width, new_height))\n",
        "\n",
        "# Отображаем измененное изображение\n",
        "display(resized_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image = Image.open('runs/segment/train7/results.png')\n",
        "scale = 0.4\n",
        "new_width = int(image.width * scale)\n",
        "new_height = int(image.height * scale)\n",
        "\n",
        "# Изменяем размер изображения\n",
        "resized_image = image.resize((new_width, new_height))\n",
        "\n",
        "# Отображаем измененное изображение\n",
        "display(resized_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "img1 = mpimg.imread('runs/segment/train7/val_batch0_labels.jpg')\n",
        "img2 = mpimg.imread('runs/segment/train7/val_batch0_pred.jpg')\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(30, 30))\n",
        "ax[0].imshow(img1)\n",
        "ax[0].axis('off')\n",
        "ax[0].set_title('labels')\n",
        "\n",
        "ax[1].imshow(img2)\n",
        "ax[1].axis('off')\n",
        "ax[1].set_title('pred')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Тестирование модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "model = YOLO('runs/segment/train7/weights/best.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.predict(source='Copernicus_NTR_LEO.2k.jpg', show=True, save=True, show_labels=True, show_conf=True, conf=0.5, save_txt=True, save_crop=False, line_width=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image = Image.open('runs/segment/predict2/Copernicus_NTR_LEO.2k.jpg')\n",
        "scale = 0.4\n",
        "new_width = int(image.width * scale)\n",
        "new_height = int(image.height * scale)\n",
        "\n",
        "# Изменяем размер изображения\n",
        "resized_image = image.resize((new_width, new_height))\n",
        "\n",
        "# Отображаем измененное изображение\n",
        "display(resized_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Путь к папке val\n",
        "val_path = 'data/val/images'\n",
        "\n",
        "# Отключить отображение предсказаний\n",
        "model.show = False\n",
        "\n",
        "# Пройтись по всем изображениям в папке val\n",
        "for filename in os.listdir(val_path):\n",
        "    if filename.endswith(\".png\"):\n",
        "        # Получить путь к изображению\n",
        "        img_path = os.path.join(val_path, filename)\n",
        "        # Сохранить предсказания в формате txt\n",
        "        model.predict(source=img_path, save_txt=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## mIoU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def txt_to_mask(txt_file, img_size, num_classes):\n",
        "    with open(txt_file, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    mask = np.zeros(img_size + (num_classes,), dtype=np.uint8)\n",
        "    for line in lines:\n",
        "        values = list(map(float, line.strip().split()))\n",
        "        class_id = int(values[0])\n",
        "        points = values[1:]\n",
        "        points = np.array(points).reshape(-1, 2)\n",
        "        points = np.rint(points * img_size[:2][::-1]).astype(np.int32)\n",
        "        points = np.concatenate([points, [points[0]]], axis=0)\n",
        "        mask_single = np.zeros(img_size[:2], dtype=np.uint8)\n",
        "        cv2.fillConvexPoly(mask_single, points, 1)\n",
        "        mask[:, :, class_id] = np.maximum(mask[:, :, class_id], mask_single)\n",
        "    return mask\n",
        "\n",
        "def calculate_iou(gt_mask, pred_mask):\n",
        "    gt_mask = gt_mask.astype(bool)\n",
        "    pred_mask = pred_mask.astype(bool)\n",
        "    intersection = np.logical_and(gt_mask, pred_mask)\n",
        "    union = np.logical_or(gt_mask, pred_mask)\n",
        "    if np.sum(union) == 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return np.sum(intersection) / np.sum(union)\n",
        "\n",
        "def calculate_miou_for_folder(gt_folder, pred_folder, img_size, num_classes):\n",
        "    gt_files = os.listdir(gt_folder)\n",
        "    gt_files = [f for f in gt_files if f.endswith('.txt')]\n",
        "    pred_files = os.listdir(pred_folder)\n",
        "    pred_files = [f for f in pred_files if f.endswith('.txt')]\n",
        "\n",
        "    gt_masks = []\n",
        "    pred_masks = []\n",
        "\n",
        "    for gt_file, pred_file in zip(gt_files, pred_files):\n",
        "        gt_path = os.path.join(gt_folder, gt_file)\n",
        "        pred_path = os.path.join(pred_folder, pred_file)\n",
        "        gt_mask = txt_to_mask(gt_path, img_size, num_classes)\n",
        "        pred_mask = txt_to_mask(pred_path, img_size, num_classes)\n",
        "        gt_masks.append(gt_mask)\n",
        "        pred_masks.append(pred_mask)\n",
        "\n",
        "    gt_masks = np.concatenate(gt_masks, axis=0)\n",
        "    pred_masks = np.concatenate(pred_masks, axis=0)\n",
        "\n",
        "    miou = calculate_iou(gt_masks, pred_masks)\n",
        "    return miou\n",
        "\n",
        "gt_folder = 'data/val/labels'\n",
        "pred_folder = 'runs/segment/predict5/labels'\n",
        "img_size = (640, 640)\n",
        "num_classes = 3\n",
        "\n",
        "miou = calculate_miou_for_folder(gt_folder, pred_folder, img_size, num_classes)\n",
        "print('mIoU:', miou)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Посмотрим в каких случаях mIoU низкий"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mask_iou = {\n",
        "    'gt_txt':{},\n",
        "    'pred_txt':{},\n",
        "    'iou':{}\n",
        "}\n",
        "\n",
        "mask_iou = pd.DataFrame(mask_iou)\n",
        "\n",
        "def calculate_iou_df(gt_folder, pred_folder, img_size, num_classes):\n",
        "    gt_files = sorted(os.listdir(gt_folder))\n",
        "    gt_files = [f for f in gt_files if f.endswith('.txt')]\n",
        "    pred_files = sorted(os.listdir(pred_folder))\n",
        "    pred_files = [f for f in pred_files if f.endswith('.txt')]\n",
        "\n",
        "    gt_masks = []\n",
        "    pred_masks = []\n",
        "\n",
        "    for gt_file, pred_file in zip(gt_files, pred_files):\n",
        "        gt_path = os.path.join(gt_folder, gt_file)\n",
        "        pred_path = os.path.join(pred_folder, pred_file)\n",
        "        gt_mask = txt_to_mask(gt_path, img_size, num_classes)\n",
        "        pred_mask = txt_to_mask(pred_path, img_size, num_classes)\n",
        "        mask_iou.loc[len(mask_iou.index)] = [gt_file, pred_file, calculate_iou(gt_mask, pred_mask)]\n",
        "\n",
        "    return mask_iou"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mask_iou = calculate_iou_df(gt_folder, pred_folder, img_size, num_classes)\n",
        "mask_iou['iou'].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mask_iou.sort_values('iou').head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred_mask = txt_to_mask('runs/segment/predict5/labels/img_resize_700.txt', img_size, num_classes)\n",
        "gt_mask = txt_to_mask('data/val/labels/img_resize_700.txt', img_size, num_classes)\n",
        "calculate_iou(gt_mask, pred_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_mask(mask, img_size):\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.imshow(mask.sum(axis=-1).reshape(img_size[0], img_size[1]))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "visualize_mask(pred_mask, img_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "visualize_mask(gt_mask, img_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image = cv2.imread('data/val/images/img_resize_700.png')\n",
        "draw_annotations(image, 'data/val/labels/img_resize_700.txt')\n",
        "draw_annotations(image, 'runs/segment/predict5/labels/img_resize_700.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image = cv2.imread('data/val/images/img_resize_815.png')\n",
        "draw_annotations(image, 'data/val/labels/img_resize_815.txt')\n",
        "draw_annotations(image, 'runs/segment/predict5/labels/img_resize_815.txt')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Satellites_segmentation",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
